# Skillix 交互式测试指南

> 文档日期：2026-01-22
> 本文档说明如何在 Cursor 中进行 Skillix 的交互式端到端测试

## 一、测试方式对比

| 测试方式 | 运行方法 | 测试内容 | 适用场景 |
|---------|---------|---------|---------|
| **自动化测试** | `npm test` | 工具层功能 | CI/CD、回归测试 |
| **交互式测试** | Cursor 对话 | 语义理解、用户体验 | 功能验证、场景演示 |

## 二、交互式测试准备

### 2.1 确保 MCP Server 已配置

检查 `~/.cursor/mcp.json` 配置：

```json
{
  "mcpServers": {
    "skillix": {
      "command": "node",
      "args": ["/path/to/skillix-mcp/dist/index.js"]
    }
  }
}
```

或者使用 npx：

```json
{
  "mcpServers": {
    "skillix": {
      "command": "npx",
      "args": ["skillix-mcp"]
    }
  }
}
```

### 2.2 构建项目

```bash
cd /path/to/skillix-mcp
npm run build
```

### 2.3 重启 Cursor

配置更改后需要重启 Cursor 以加载 MCP 工具。

---

## 三、交互式测试场景

### 测试场景 1：技能发现

**目的**：验证 AI 能否根据用户需求找到匹配的技能

**测试步骤**：

1. 在 Cursor 中打开对话
2. 输入以下内容：

```
我需要处理 PDF 文件，有没有相关的技能？
```

**期望结果**：
- AI 调用 `sx-dispatch` 分析需求
- 返回匹配的技能列表
- 如果没有匹配，建议创建新技能

**验证点**：
- [ ] AI 理解了"处理 PDF 文件"的意图
- [ ] 调用了正确的工具
- [ ] 返回了相关技能或创建建议

---

### 测试场景 2：技能创建（AI First 模式）

**目的**：验证 AI 能否引导用户创建新技能

**测试步骤**：

1. 在 Cursor 中输入：

```
帮我创建一个代码审查技能
```

**期望结果**：
- AI 识别用户意图是创建技能
- AI 调用 `sx-help topic=skill` 获取引导流程
- AI 开始引导对话：
  - "这个技能要解决什么问题？"
  - "什么情况下会触发这个技能？"
  - "需要执行哪些具体操作？"
  - ...
- 收集完信息后，调用 `sx-skill action=create`

**验证点**：
- [ ] AI 进行了对话引导
- [ ] 收集了必要信息
- [ ] 成功创建了技能
- [ ] 技能内容符合用户需求

---

### 测试场景 3：技能使用

**目的**：验证用户能否使用已有技能

**测试步骤**：

1. 先确保有技能存在（可以先创建一个）
2. 在 Cursor 中输入：

```
帮我查看 pdf-converter 技能的使用方法
```

**期望结果**：
- AI 调用 `sx-skill action=read name=pdf-converter`
- 返回技能的内容和使用指南

**验证点**：
- [ ] 正确读取了技能内容
- [ ] 展示了使用方法

---

### 测试场景 4：技能列表

**目的**：验证用户能否查看所有技能

**测试步骤**：

1. 在 Cursor 中输入：

```
列出所有可用的技能
```

**期望结果**：
- AI 调用 `sx-skill action=list`
- 返回全局和项目级技能列表

**验证点**：
- [ ] 列出了所有技能
- [ ] 区分了全局和项目级

---

### 测试场景 5：技能更新

**目的**：验证用户能否更新现有技能

**测试步骤**：

1. 在 Cursor 中输入：

```
更新 pdf-converter 技能，添加批量处理功能
```

**期望结果**：
- AI 识别更新意图
- 读取现有技能内容
- 引导用户确认更新内容
- 调用 `sx-skill action=update`

**验证点**：
- [ ] 正确识别了更新意图
- [ ] 保留了原有内容
- [ ] 添加了新功能

---

### 测试场景 6：技能删除

**目的**：验证用户能否删除技能

**测试步骤**：

1. 在 Cursor 中输入：

```
删除 test-skill 技能
```

**期望结果**：
- AI 确认删除操作
- 调用 `sx-skill action=delete name=test-skill`

**验证点**：
- [ ] 进行了确认
- [ ] 成功删除

---

### 测试场景 7：帮助信息

**目的**：验证帮助系统是否正常

**测试步骤**：

1. 在 Cursor 中输入：

```
Skillix 怎么用？
```

**期望结果**：
- AI 调用 `sx-help topic=overview`
- 返回系统概述和使用说明

**验证点**：
- [ ] 返回了帮助信息
- [ ] 内容清晰易懂

---

## 四、完整测试流程

### 4.1 测试脚本（复制到 Cursor 执行）

```markdown
# Skillix 端到端测试

## 测试 1：查看帮助
请告诉我 Skillix 是什么，怎么使用？

## 测试 2：列出技能
列出当前所有可用的技能

## 测试 3：创建技能
帮我创建一个 Git 提交分析技能，用于统计提交历史

## 测试 4：查看技能
查看刚才创建的 git-analyzer 技能

## 测试 5：搜索技能
我需要分析代码提交记录，有什么技能可以用？

## 测试 6：更新技能
更新 git-analyzer 技能，添加按作者统计的功能

## 测试 7：删除技能
删除 git-analyzer 技能

## 测试 8：验证删除
再次列出所有技能，确认删除成功
```

### 4.2 逐步执行

1. 复制上面的测试脚本
2. 在 Cursor 中逐个执行每个测试
3. 记录每个测试的结果
4. 检查是否符合期望

---

## 五、测试结果记录模板

```markdown
# Skillix 交互式测试结果

测试日期：____年__月__日
测试人员：____________

## 测试环境
- Cursor 版本：_______
- Skillix 版本：_______
- 操作系统：_______

## 测试结果

| 测试场景 | 结果 | 备注 |
|---------|------|------|
| 查看帮助 | ✅/❌ | |
| 列出技能 | ✅/❌ | |
| 创建技能 | ✅/❌ | |
| 查看技能 | ✅/❌ | |
| 搜索技能 | ✅/❌ | |
| 更新技能 | ✅/❌ | |
| 删除技能 | ✅/❌ | |

## 问题记录
1. 
2. 

## 改进建议
1. 
2. 
```

---

## 六、常见问题

### Q1: MCP 工具没有加载

**症状**：Cursor 中无法调用 sx-* 工具

**解决**：
1. 检查 `~/.cursor/mcp.json` 配置
2. 确保项目已构建 (`npm run build`)
3. 重启 Cursor

### Q2: AI 没有进行对话引导

**症状**：创建技能时 AI 直接创建，没有询问详情

**解决**：
1. 检查工具描述是否包含 AI First 提示
2. 尝试更模糊的需求描述
3. 明确要求 AI 引导

### Q3: 技能搜索不准确

**症状**：搜索结果与需求不匹配

**解决**：
1. 检查技能的 description 和 tags
2. 使用更具体的关键词
3. 检查分流算法

---

## 七、总结

交互式测试是验证 Skillix **语义理解能力**和**用户体验**的重要方式。

通过在 Cursor 中执行真实的用户场景，可以：
1. 验证 AI 是否正确理解用户意图
2. 验证对话引导是否流畅
3. 验证技能管理功能是否正常
4. 发现自动化测试无法覆盖的问题

建议定期进行交互式测试，特别是在：
- 发布新版本前
- 修改工具描述后
- 优化分流算法后
